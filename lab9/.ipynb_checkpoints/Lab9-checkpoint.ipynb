{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import IPython\n",
    "import scipy.io.wavfile\n",
    "import scipy.signal as sig\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as rng\n",
    "import os\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.mixture import GaussianMixture "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STFT code from lab 1\n",
    "from numpy.fft import rfft, irfft, fftfreq\n",
    "def foward_transform(input_sound, dft_size, hop_size, zero_pad, window):\n",
    "    input_len = len(input_sound)\n",
    "    idx = 0\n",
    "    segments = []\n",
    "    while idx+dft_size < input_len:\n",
    "        s = input_sound[idx:idx+dft_size]\n",
    "        segments.append(np.multiply(s, window))\n",
    "        idx += hop_size\n",
    "    else:\n",
    "        s = np.append(input_sound[idx:-1], np.zeros(idx+dft_size-input_len+1))\n",
    "        segments.append(np.multiply(s, window))\n",
    "    frames = np.array(segments)\n",
    "    \n",
    "    dft_frames = []\n",
    "    for idx, x in enumerate(frames):\n",
    "        dft_frames.append(rfft(x, dft_size + zero_pad))\n",
    "    dft_frames = np.array(dft_frames, dtype=complex)\n",
    "    return dft_frames \n",
    "\n",
    "def inverse_transform(input_sound, dft_size, hop_size, zero_pad, window):\n",
    "    leng = hop_size*(len(input_sound)-1)+dft_size+zero_pad\n",
    "    output = np.zeros(leng, dtype=complex)\n",
    "    for idx, row in enumerate(input_sound):\n",
    "        frame = np.multiply(irfft(row, dft_size+zero_pad)[:dft_size], window)\n",
    "        output[idx*hop_size:idx*hop_size+dft_size] += frame\n",
    "    return output\n",
    "\n",
    "def stft( input_sound, dft_size, hop_size, zero_pad, window):\n",
    "    if input_sound.ndim == 1 and np.isreal(input_sound).all():\n",
    "        return foward_transform(input_sound, dft_size, hop_size, zero_pad, window)\n",
    "    else:\n",
    "        return inverse_transform(input_sound, dft_size, hop_size, zero_pad, window)\n",
    "    \n",
    "def plot_stft( input_sound, stft, dft_size, hop_size, zero_pad, frate, title=\"\"):\n",
    "    output = np.absolute(stft)**0.3\n",
    "    time = np.linspace(0, output.shape[0] * hop_size / frate,output.shape[0])\n",
    "    freq = np.linspace(0, frate/2, int((dft_size+zero_pad)/2 + 1))\n",
    "    plt.pcolormesh(time, freq, output.T)\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Frequency (HZ)\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_sound( input_sound, fs, title='input_sound'):\n",
    "    plt.plot(np.linspace(0, len(input_sound)/fs, len(input_sound)), input_sound)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.show()\n",
    "    \n",
    "def process(input_sound):\n",
    "    dft_size = 1024\n",
    "    Hann_window = np.hanning(dft_size)\n",
    "    hop_size = 128\n",
    "    zero_pad = 0\n",
    "    stft_ = stft(input_sound, dft_size, hop_size, zero_pad, Hann_window)\n",
    "    return np.absolute(stft_)**0.3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "frate = 0\n",
    "speech_file = []\n",
    "for filename in os.listdir(\"./data/SpeechMusic/speech\"):\n",
    "    frate, file = scipy.io.wavfile.read(\"./data/SpeechMusic/speech/\"+filename)\n",
    "    speech_file.append(process(file))\n",
    "    \n",
    "music_file = []\n",
    "for filename in os.listdir(\"./data/SpeechMusic/music\"):\n",
    "    frate, file = scipy.io.wavfile.read(\"./data/SpeechMusic/music/\"+filename)\n",
    "    music_file.append(process(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Finale\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "speech_train, speech_test, music_train, music_test = train_test_split( speech_file, music_file, train_size=50, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_train = np.concatenate(np.array(speech_train), axis=0)\n",
    "music_train = np.concatenate(np.array(music_train), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_speech = GaussianMixture(5, \"diag\")\n",
    "gm_speech = gm_speech.fit(speech_train)\n",
    "gm_music = GaussianMixture(5, \"diag\")\n",
    "gm_music = gm_music.fit(music_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for speech in speech_test:\n",
    "    correct += 1 if gm_speech.score(speech) > gm_music.score(speech) else 0\n",
    "for music in music_test:\n",
    "    correct += 1 if gm_speech.score(music) < gm_music.score(music) else 0\n",
    "accuracy = correct/(len(speech_test)+len(music_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 19 Test Size: 20 Accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "print(\"Correct:\",correct,\"Test Size:\",(len(speech_test)+len(music_test)),\"Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have ran the code several times and the accuracy varies a lot from 0.65 to 0.95 due to different train/test sets. I set a random_state in test_train_split to fix the data set in order to better optimize the model. On avrage the accuracy would be around 0.85~0.9 or so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dir_name):\n",
    "    frate = 1293\n",
    "    arr_file = []\n",
    "    for filename in os.listdir(\"./data/genres/\"+dir_name):\n",
    "        file, frate = librosa.core.load(\"./data/genres/\"+dir_name+\"/\"+filename)\n",
    "        file = np.array(file)\n",
    "        mfcc = np.array(librosa.feature.mfcc(file, frate, n_mfcc=60))\n",
    "        arr_file.append(mfcc)\n",
    "    train, test = train_test_split(arr_file, test_size=0.5, random_state=35)\n",
    "    train = np.concatenate(train, axis=1)\n",
    "    return train, test, frate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "frate = 0\n",
    "classical_train, classical_test, frate = get_data('classical')\n",
    "disco_train, disco_test, frate = get_data('disco')\n",
    "metal_train, metal_test, frate = get_data('metal')\n",
    "pop_train, pop_test, frate = get_data('pop')\n",
    "reggae_train, reggae_test, frate = get_data('reggae')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a GaussianMixture classifier for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_classical = GaussianMixture(10, \"diag\")\n",
    "gm_classical = gm_classical.fit(classical_train.T)\n",
    "gm_disco = GaussianMixture(10, \"diag\")\n",
    "gm_disco = gm_disco.fit(disco_train.T)\n",
    "gm_metal = GaussianMixture(10, \"diag\")\n",
    "gm_metal = gm_metal.fit(metal_train.T)\n",
    "gm_pop = GaussianMixture(10, \"diag\")\n",
    "gm_pop = gm_pop.fit(pop_train.T)\n",
    "gm_reggae = GaussianMixture(10, \"diag\")\n",
    "gm_reggae = gm_reggae.fit(reggae_train.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evalutate our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test_arr ,gm_arr):\n",
    "    correct = 0\n",
    "    for idx, class_ in enumerate(test_arr):\n",
    "        for file in class_:\n",
    "            scores = [gm.score(file.T) for gm in gm_arr]\n",
    "            if np.argmax(scores) == idx:\n",
    "                correct += 1\n",
    "    return correct/ np.sum([len(x) for x in test_arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracay:  0.832\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracay: \",evaluate([classical_test, disco_test, metal_test, pop_test, reggae_test],[gm_classical, gm_disco, gm_metal, gm_pop, gm_reggae]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Part1 I improved the accuracy from 0.9 to 0.95 by using more guassian components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use other classifiers, instead of training a classifier for each class, I am using one single classifier that can directly predict different classes. I appended the training data and provided the corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.append(speech_train, music_train, axis=0)\n",
    "y = np.append(np.zeros(speech_train.shape[0]), np.ones(music_train.shape[0]), axis=0)\n",
    "# X is the combined train data\n",
    "# y is the array of labels: 0 means speech, 1 means music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def part3_eval(speech_clf, speech_test, music_test):\n",
    "    speech_clf = speech_clf.fit(X, y)\n",
    "    correct = 0\n",
    "    for speech in speech_test:\n",
    "        res = speech_clf.predict(speech)\n",
    "        if np.count_nonzero(res) < 0.5*len(res):\n",
    "            correct += 1\n",
    "    for music in music_test:\n",
    "        res = speech_clf.predict(music)\n",
    "        if np.count_nonzero(res) > 0.5*len(res):\n",
    "            correct += 1\n",
    "    accuracy = correct/(len(speech_test)+len(music_test))\n",
    "    print(\"Correct:\",correct,\"Test Size:\",(len(speech_test)+len(music_test)),\"Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 19 Test Size: 20 Accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "speech_clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(15,))\n",
    "part3_eval(speech_clf, speech_test, music_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 18 Test Size: 20 Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "speech_clf = DecisionTreeClassifier(random_state=0)\n",
    "part3_eval(speech_clf, speech_test, music_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 18 Test Size: 20 Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "speech_clf = GradientBoostingClassifier()\n",
    "part3_eval(speech_clf, speech_test, music_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried using different classifiers like DecisionTreeClassifier, GradientBoostingClassifier, RandomForestClassifier  but they did not seem to have better performance since the performance was already very good. (And the test dataset is too small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving part 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found out that the accuracy would improve a lot when I use more components in the GuassianMixture. Therefore I set the component number to 10. This has improved the accuracy from 0.75 to 0.816. Furthermore, I used more components (80) in mfcc and this improved the accuracy to 0.832."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose not to use other classifiers for part 2 because there are too many train data and it takes too long to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
